for oral 
Assignment 1>
//yytext: yytext is a character array that contains the text of the most recently matched token. Whenever a pattern in the Lex specification matches input text, yytext holds that text.
//yywrap(): yywrap() is a function that controls what happens when the end of the input stream is reached. It returns 1 if there's more input to process and 0 when there's no more input.
By default, if you don't define yywrap(), it returns 1, indicating there's no more input. You can override this function to customize end-of-file handling, like switching to another input source.
//yyin: yyin is a FILE pointer representing the input stream. By default, Lex sets yyin to stdin, but you can change it to read from a file or any other input source.
//yylex(): yylex() is the main function generated by Lex. It performs lexical analysis by scanning the input and matching patterns defined in the Lex specification. When you call yylex(),
 it returns the next token found in the input stream. The type of token returned depends on the rules defined in the Lex file.

//tokens:-In Lex, a token is a sequence of characters in the input text that matches a specified pattern defined in the Lex specification file. 
Each token typically represents a lexical unit or a meaningful component of the input, such as a keyword, identifier, number, or symbol.
//lexeme:lexical analyzer reads stream of characters making up source program and group character in meaningful sequence called lexeme.
for each lexeme lexical analyzer produce token as output.
 
1> lex is a tool for genrating lexical analyzers also known as lexers or tokenizers
-input of lex is set of regular EXPRESSION
-output of lex is lexical analyzers
-lex is a computer program that genrates lexical analyzers.
-lex is commonly used with the yacc parser genrator

2> Yacc is a tool of genrating parsers for content tree grammers.
-yacc takes a format grammer specification & associated action as input & generates c code for parser
-input of yacc is the rule or grammer
-output of yacc is c code for parser(c program)
-$ in yacc represents the value returned by the complete action.

compiler steps===and inputs==
/*
lex file n.l/lex
gcc lex.yy.c
./a.out
==output
*/

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Assignment 2>
//yytext: yytext is a character array that contains the text of the most recently matched token. Whenever a pattern in the Lex specification matches input text, yytext holds that text.
//yywrap(): yywrap() is a function that controls what happens when the end of the input stream is reached. It returns 1 if there's more input to process and 0 when there's no more input. 
By default, if you don't define yywrap(), it returns 1, indicating there's no more input. You can override this function to customize end-of-file handling, like switching to another input source.
//yyin: yyin is a FILE pointer representing the input stream. By default, Lex sets yyin to stdin, but you can change it to read from a file or any other input source.
//yylex(): yylex() is the main function generated by Lex. It performs lexical analysis by scanning the input and matching patterns defined in the Lex specification. When you call yylex(), 
it returns the next token found in the input stream. The type of token returned depends on the rules defined in the Lex file.

//tokens:-In Lex, a token is a sequence of characters in the input text that matches a specified pattern defined in the Lex specification file. 
Each token typically represents a lexical unit or a meaningful component of the input, such as a keyword, identifier, number, or symbol.
//lexeme:lexical analyzer reads stream of characters making up source program and group character in meaningful sequence called lexeme. 
for each lexeme lexical analyzer produce token as output.

1> lex is a tool for genrating lexical analyzers also known as lexers or tokenizers
-input of lex is set of regular EXPRESSION
-output of lex is lexical analyzers
-lex is a computer program that genrates lexical analyzers.
-lex is commonly used with the yacc parser genrator

2> Yacc is a tool of genrating parsers for content tree grammers.
-yacc takes a format grammer specification & associated action as input & generates c code for parser
-input of yacc is the rule or grammer
-output of yacc is c code for parser(c program)
-$ in yacc represents the value returned by the complete action.
 
compiler steps===and inputs==
/*
lex file n.l/lex
gcc lex.yy.c
./a.out
==output
*/

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Assignment 3>
// 1>
syntax analysis ===>>  in the syntax analysis phase a compiler verifies wheather or not the tokens generated by lexical analyzer are grouped
according to the syntatic rules of the language
2>
syntax analysis is done by parser
3>
the parser obtain a string of tokens from the lexical analyzer and verifies that the grammer for the source language

*> Lex program generates token and accept that generated tokens or context free grammer if will in Statements

**>> function in yacc
1>> YY Parse 
-it is entry point of yacc program
-it is used to demand tokens the program
-

2>> YY error
-YY error is function in the Yacc called when a parsing error is this 
- it is used to print error message take other appropriate action 
 
 3>> Yacc source files has three main sections divide by %%
  1>first section contain defination & declaration used by Yacc & generated code
  2>the Second section contain the grammer of rules and associated semantic actions 
  3>the third section can contain additional c code to be copied directly to output file
  //


  1>> LEX (lexer genrator)
1> lex is a tool for genrating lexical analyzers also known as lexers or tokenizers.
-input of lex is set of regular EXPRESSION
-output of lex is lexical analyzers
-lex is a computer program that genrates lexical analyzers.
-lex is commonly used with the yacc parser genrator

2>> Yacc (parser genrate)
-Yacc is a tool of genrating parsers for content tree grammers.
-yacc takes a format grammer specification & associated action as input & generates c code for parser
-input of yacc is the rule or grammer
-output of yacc is c code for parser(c program)
-$ in yacc represents the value returned by the complete action.
//

compiler steps===and inputs
compile inputs  =
lex lflie name.lex
gcc lex.yy.c y.tab.c    =lex and yac both compilation
./a.out

or 
lex filename.l         =>o/p is lex.y
yacc -d filename.y     =>compilation yacc y.tab.c
cc.lex.yy.c y.tab.c    =>generated obj file.
./a.out

input= int a=10;
  */                    

input int a,b,c


<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Assignment 4>
// 1>
syntax analysis ===>>  in the syntax analysis phase a compiler verifies wheather or not the tokens generated by lexical analyzer are grouped
according to the syntatic rules of the language
2>
syntax analysis is done by parser
3>
the parser obtain a string of tokens from the lexical analyzer and verifies that the grammer for the source language

*> Lex program generates token and accept that generated tokens or context free grammer if will in Statements

**>> function in yacc
1>> YY Parse 
-it is entry point of yacc program
-it is used to demand tokens the program
-

2>> YY error
-YY error is function in the Yacc called when a parsing error is this 
- it is used to print error message take other appropriate action 
 
 3>> Yacc source files has three main sections divide by %%
  1>first section contain defination & declaration used by Yacc & generated code
  2>the Second section contain the grammer of rules and associated semantic actions 
  3>the third section can contain additional c code to be copied directly to output file
  //
  compiler steps===and inputs
  /*
  lex filen.lex
  gcc lex.yy.c y.tab.c
  ./a.out
  
  
  lex lflie name.lex
  gcc lex.yy.c y.tab.c    =lex and yac both compilation
  ./a.out
  
  ip= i am sanket.=== Simple Sentence
   
   i am sanket and/or/but am a boy.=====compound sentences.
  
  */

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Assignment 5>
//
What is a parser?
-parsing is the process of analyzing a string of symbols, special characters, or data structures to conform to the rules of a formal grammar. This process is also known as syntax analysis or syntactic analysis. 
what is top down parser?
-A top-down parser is a software application that is part of a compiler and is used to analyze code during the compilation process. 
-It's a parsing technique that starts with the highest-level grammar rule and recursively expands it until the input string is parsed.
Recursive descent parser?
-A recursive descent parser (RDP) is a parsing technique used in computer science to analyze and process a language's syntax. 
-It's a type of top-down parser that starts at the highest level of the syntax and recursively descends through each production rule until reaching the final token in the language. 
Non terminals=E,E',T,T',F
terminals= +, *, (, ), id

//
compiler steps===and inputs
//g++ rdp.c
//./a.out
// ouput is genetared by the code
  
  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

  Assignment 6>
// 1>
syntax analysis ===>>  in the syntax analysis phase a compiler verifies wheather or not the tokens generated by lexical analyzer are grouped
according to the syntatic rules of the language
2>
syntax analysis is done by parser
3>
the parser obtain a string of tokens from the lexical analyzer and verifies that the grammer for the source language

*> Lex program generates token and accept that generated tokens or context free grammer if will in Statements

**>> function in yacc
1>> YY Parse 
-it is entry point of yacc program
-it is used to demand tokens the program
-

2>> YY error
-YY error is function in the Yacc called when a parsing error is this 
- it is used to print error message take other appropriate action 
 
 3>> Yacc source files has three main sections divide by %%
  1>first section contain defination & declaration used by Yacc & generated code
  2>the Second section contain the grammer of rules and associated semantic actions 
  3>the third section can contain additional c code to be copied directly to output file
  //

  compiler steps===and inputs

  /*
  inputs=
  2+3
  8-9
  8/9
  8*8
  
  lex fn.lex
  gcc lex.yy.c y.tab.c
  ./a.out
  
  */

  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

  Assignment 7>
 
// 
1>> LEX (lexer genrator)
1> lex is a tool for genrating lexical analyzers also known as lexers or tokenizers.
-input of lex is set of regular EXPRESSION
-output of lex is lexical analyzers
-lex is a computer program that genrates lexical analyzers.
-lex is commonly used with the yacc parser genrator

2>> Yacc (parser genrate)
-Yacc is a tool of genrating parsers for content tree grammers.
-yacc takes a format grammer specification & associated action as input & generates c code for parser
-input of yacc is the rule or grammer
-output of yacc is c code for parser(c program)
-$ in yacc represents the value returned by the complete action.

compiler steps===and inputs

\*
  lex filename.lex
gcc lex.yy.c y.tab.c
./a.out

  input== int 5
$
print
*/

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Assignment 8>

oral
//
What is intermediate code? Ans: During the translation of a source program into the object code for a target machine, 
a compiler may generate a middle-level language code, which is known as intermediate code or intermediate text.
 The complexity of this code lies between the source language code and the object code.


 compiler steps===and inputs=
 \*
lex fn.lex
gcc lex.yy.c y.tab.c
./a.out

input ==a=b*c+d;
*/

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Assignment 9>
oral 
what is assembler
assembler is convert assembly language into machine language
pass 1
Checks to see if the instructions are legal in the current assembly mode. 
Allocates space for instructions and storage areas you request. Fills in the values of constants, where possible.
pass 2
of assembler generates machine code by converting symbolic machine-opcodes into their respective bit configuration(machine understandable form). 
It stores all machine-opcodes in MOT table (op-code table) with symbolic code, their length and their bit configuration.

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

Assignment 10>

oral
A microprocessor is a computer processor for which the data processing logic and control is included on a single integrated circuit (IC), or a small number of ICs.
 The microprocessor contains the arithmetic, logic, and control circuitry required to perform the functions of a computer's central processing unit (CPU).

Pass 1
scans the input line-by-line and defines macros
or
macro definitions are stored in a macro definition table and names are entered in a macro name table
pass 2
a program that copies text from one place to another, while making systematic replacements along the way. 
It's used to identify macro names and perform expansion in source code before it's compiled or assembled.
or
macro calls are identified and replaced by retrieving the corresponding macro definition from the tables and substituting arguments.

<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<===>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

