%{
  #include<stdio.h>
%}
%%
[\/*].*[\*/] {printf("\n%s is Multiline comment",yytext);}
"#" {printf("\n%s is Preprocesssor statement",yytext);}
[a-z]+[\.][h] {printf("\n%s is Header file",yytext);}
"int"|"float"|"double"|"printf"|"scanf"|"void"|"main" {printf("\n%s is Keyword",yytext);}
[a-zA-Z_][a-zA-Z_0-9]* {printf("\n%s is an Identifier",yytext);}
"+"|"-"|"=" {printf("\n%s is an Operator",yytext);}
[0-9]+ {printf("\n%s is Number",yytext);}
[0-9]+[\.][0-9]+ {printf("\n%s is Number",yytext);}
";"|","|"("|")"|"["|"]"|"{"|"}"|"<"|">" {printf("\n%s is Punctuation",yytext);}
["].*["] {printf("\n%s is Literals",yytext);}
"//".*"\n" {printf("\n%s is Comment",yytext);}
%%
int yywrap()
{
 return 1;
}
int main()
{
 yyin=fopen("Ass1.c","r");
 yylex();
 return 1;
}
//yytext: yytext is a character array that contains the text of the most recently matched token. Whenever a pattern in the Lex specification matches input text, yytext holds that text.
//yywrap(): yywrap() is a function that controls what happens when the end of the input stream is reached. It returns 1 if there's more input to process and 0 when there's no more input. By default, if you don't define yywrap(), it returns 1, indicating there's no more input. You can override this function to customize end-of-file handling, like switching to another input source.
//yyin: yyin is a FILE pointer representing the input stream. By default, Lex sets yyin to stdin, but you can change it to read from a file or any other input source.
//yylex(): yylex() is the main function generated by Lex. It performs lexical analysis by scanning the input and matching patterns defined in the Lex specification. When you call yylex(), it returns the next token found in the input stream. The type of token returned depends on the rules defined in the Lex file.

//tokens:-In Lex, a token is a sequence of characters in the input text that matches a specified pattern defined in the Lex specification file. Each token typically represents a lexical unit or a meaningful component of the input, such as a keyword, identifier, number, or symbol.
//lexeme:lexical analyzer reads stream of characters making up source program and group character in meaningful sequence called lexeme. for each lexeme lexical analyzer produce token as output.
 
1> lex is a tool for genrating lexical analyzers also known as lexers or tokenizers
-input of lex is set of regular EXPRESSION
-output of lex is lexical analyzers
-lex is a computer program that genrates lexical analyzers.
-lex is commonly used with the yacc parser genrator

2> Yacc is a tool of genrating parsers for content tree grammers.
-yacc takes a format grammer specification & associated action as input & generates c code for parser
-input of yacc is the rule or grammer
-output of yacc is c code for parser(c program)
-$ in yacc represents the value returned by the complete action.

/*
lex file n.l/lex
gcc lex.yy.c
./a.out
==output
*/